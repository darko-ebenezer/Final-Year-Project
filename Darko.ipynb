{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mvp8TC_ZqatInfWoAiwmCUL1GSPTJTrK",
      "authorship_tag": "ABX9TyMP2xaLaoVvAW1CsxHgK22n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darko-ebenezer/Final-Year-Project/blob/main/Darko.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "11kdY8zWOzdT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import graphviz\n",
        "from sklearn import model_selection\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier as MLPC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def compareABunchOfDifferentModelsAccuracy(a, b, c, d):\n",
        "    \"\"\"\n",
        "    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n",
        "    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
        "    http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
        "    \"\"\"\n",
        "    print('\\nCompare Multiple Classifiers: \\n')\n",
        "    print('K-Fold Cross-Validation Accuracy: \\n')\n",
        "    names = []\n",
        "    models = []\n",
        "    resultsAccuracy = []\n",
        "    models.append(('LR', LogisticRegression()))\n",
        "    models.append(('RF', RandomForestClassifier()))\n",
        "    models.append(('KNN', KNeighborsClassifier()))\n",
        "    models.append(('SVM', SVC()))\n",
        "    models.append(('LSVM', LinearSVC()))\n",
        "    models.append(('GNB', GaussianNB()))\n",
        "    models.append(('DTC', DecisionTreeClassifier()))\n",
        "    models.append(('GBC', GradientBoostingClassifier()))\n",
        "    for name, model in models:\n",
        "        model.fit(a, b)\n",
        "        kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n",
        "        resultsAccuracy.append(accuracy_results)\n",
        "        names.append(name)\n",
        "        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n",
        "        print(accuracyMessage)\n",
        "    # Boxplot\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle('Algorithm Comparison: Accuracy')\n",
        "    ax = fig.add_subplot(111)\n",
        "    plt.boxplot(resultsAccuracy)\n",
        "    ax.set_xticklabels(names)\n",
        "    ax.set_ylabel('Cross-Validation: Accuracy Score')\n",
        "    plt.show()\n",
        "\n",
        "def defineModels():\n",
        "    print('\\nLR = LogisticRegression')\n",
        "    print('RF = RandomForestClassifier')\n",
        "    print('KNN = KNeighborsClassifier')\n",
        "    print('SVM = Support Vector Machine SVC')\n",
        "    print('LSVM = LinearSVC')\n",
        "    print('GNB = GaussianNB')\n",
        "    print('DTC = DecisionTreeClassifier')\n",
        "    print('GBC = GradientBoostingClassifier \\n\\n')\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"MLPClassifier\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(kernel=\"linear\"),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    GaussianProcessClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    MLPClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "dict_characters = {0: 'Healthy', 1: 'Diabetes'}"
      ],
      "metadata": {
        "id": "u9fDmxhPPPXT"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}